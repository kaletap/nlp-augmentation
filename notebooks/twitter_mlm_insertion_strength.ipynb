{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "twitter_mlm_insertion_strength.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqp4A6lcASV6"
      },
      "source": [
        "# IMDB: MLM Insertion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWtJcEfMpygI",
        "outputId": "c6faf96d-97b1-4b94-90bc-f77769c92aac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import json\n",
        "import heapq\n",
        "import os\n",
        "import random\n",
        "from typing import List\n",
        "\n",
        "%pip install -U datasets\n",
        "%pip install transformers\n",
        "import torch\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoModelForMaskedLM, AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "ROOT_DIR = \"drive/My Drive/Colab Notebooks/nlp/results/twitter_mlm_insertion\"\n",
        "if not os.path.exists(ROOT_DIR):\n",
        "    os.mkdir(ROOT_DIR)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: datasets in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.10)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.4)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: xxhash in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from datasets) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: pyarrow>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZW4JvsPxhff"
      },
      "source": [
        "## Defining augmentation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9a5MnCnxkNO"
      },
      "source": [
        "class MLMInsertionAugmenter:\n",
        "    def __init__(self, model, tokenizer, p: float, min_mask: int = 1, topk: int = 5, uniform: bool = False, device=None):\n",
        "        self.device = device or torch.device('cpu')\n",
        "        self.model = model.eval().to(self.device)\n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab_words = list(tokenizer.get_vocab().keys())\n",
        "        self.mask_token = tokenizer.mask_token\n",
        "        self.mask_token_id = tokenizer.mask_token_id\n",
        "        self.topk = topk\n",
        "        self.min_mask = min_mask\n",
        "        self.uniform = uniform\n",
        "        self.p = p\n",
        "        \n",
        "    def __call__(self, text: str):\n",
        "        if self.p == 0:\n",
        "            return text\n",
        "        words = np.array(text.split(), dtype='object')\n",
        "        n_mask = max(self.min_mask, int(len(words) * self.p))\n",
        "        masked_indices = np.sort(np.random.choice(len(words) + 1, size=n_mask))\n",
        "\n",
        "        masked_words = np.insert(words, masked_indices, self.mask_token)\n",
        "        masked_text = \" \".join(masked_words)\n",
        "        \n",
        "        tokenizer_output = self.tokenizer([masked_text])\n",
        "        input_ids = torch.tensor(tokenizer_output['input_ids']).to(self.device)\n",
        "        attention_mask = torch.tensor(tokenizer_output['attention_mask']).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            output = self.model(input_ids)\n",
        "            predicted_logits = output.logits[input_ids == self.mask_token_id]\n",
        "            predicted_probas = predicted_logits.softmax(1)\n",
        "            \n",
        "        predicted_words = [self.sample_word(probas).strip() for probas in predicted_probas]\n",
        "        \n",
        "        new_words = np.insert(words, masked_indices, predicted_words)\n",
        "        new_text = \" \".join(new_words)\n",
        "        return new_text\n",
        "    \n",
        "    \n",
        "    def sample_word(self, predicted_probas):\n",
        "        if hasattr(predicted_probas, 'tolist'):\n",
        "            predicted_probas = predicted_probas.tolist()\n",
        "        most_probable = heapq.nlargest(self.topk, zip(self.vocab_words, predicted_probas), key=lambda t: t[1])\n",
        "        words, probas = zip(*most_probable)\n",
        "        word = random.choice(words) if self.uniform else random.choices(words, weights=probas)[0]\n",
        "        return self.tokenizer.convert_tokens_to_string(word).strip()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEFFI0Kdp4k6"
      },
      "source": [
        "class DatasetWithAugmentation(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, augmenter, augmentation_prob: float = 0.9):\n",
        "        self.dataset = dataset\n",
        "        self.augmenter = augmenter\n",
        "        self.augmentation_prob = augmentation_prob\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        try:\n",
        "            item = self.dataset[i]\n",
        "            if random.random() < self.augmentation_prob:\n",
        "                item['text'] = self.augmenter(item['text'])\n",
        "            return item\n",
        "        except:\n",
        "            print(item)\n",
        "            raise Exception(f\"Something went wrong when augmenting item number {i}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "def get_datasets(dataset_name, augmenter, train_size, val_size=5_000, test_size=None, augmentation_prob=0.5, random_seed: int = 42):\n",
        "    \"\"\"Returns a tuple of train, validation and test datasets of sizes determined by arguments.\"\"\"\n",
        "    dataset = load_dataset(dataset_name, split=\"train\")\n",
        "    # We want test and validation data to be the same for every experiment\n",
        "    test_split = dataset.train_test_split(test_size=test_size, seed=random_seed)\n",
        "    test_dataset = test_split[\"test\"]\n",
        "    train_val_split = test_split[\"train\"].train_test_split(test_size=val_size, seed=random_seed)\n",
        "    # Validation and test sets\n",
        "    train_dataset = train_val_split[\"train\"].train_test_split(train_size=train_size, seed=random_seed)[\"train\"]\n",
        "    train_dataset = DatasetWithAugmentation(train_dataset, augmenter, augmentation_prob=augmentation_prob)\n",
        "    val_dataset = train_val_split[\"test\"]\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "class DataCollator:\n",
        "    def __init__(self, tokenizer, label_colname='label'):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.label_colname = label_colname\n",
        "        \n",
        "    def __call__(self, examples: List[dict]):\n",
        "        labels = [0 if example['sentiment'] == 0 else 1 for example in examples]\n",
        "        texts = [example['text'] for example in examples]\n",
        "        tokenizer_output = self.tokenizer(texts, truncation=True, padding=True)\n",
        "        return {\n",
        "            'labels': torch.tensor(labels), \n",
        "            'input_ids': torch.tensor(tokenizer_output['input_ids']), \n",
        "            'attention_mask': torch.tensor(tokenizer_output['attention_mask'])\n",
        "            }\n",
        "\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='binary', zero_division=0)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'f1': f1,\n",
        "        'precision': precision,\n",
        "        'recall': recall\n",
        "    }"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW2d5HGCqTTb",
        "outputId": "0e5f0ee7-07e7-4a90-acfc-92e0fe4a285a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "AUGMENTATION_PROB = 0.7\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base', use_fast=False)  # we cannot use Fast tokenizer for MLMInsertionAugmenter\n",
        "data_collator = DataCollator(tokenizer, 'sentiment')\n",
        "\n",
        "device = torch.device('cuda')\n",
        "mlm_model = AutoModelForMaskedLM.from_pretrained('roberta-base', return_dict=True).eval()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['lm_head.decoder.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwhkqPjlI35c"
      },
      "source": [
        "augmenter = MLMInsertionAugmenter(mlm_model, tokenizer, 0.2, min_mask=1, topk=10, uniform=False, device=torch.device('cuda'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ANBvl4Hj4e4B",
        "outputId": "e83ea733-8061-4f3a-807d-686cad990fcc",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "augmenter('I love you ')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I love you .'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld0FI0F7qhMm",
        "outputId": "da073904-b550-4b75-d947-01a01e645b01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_size = 100\n",
        "\n",
        "FRACTIONS = [0.0, 0.01, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6]\n",
        "accuracies = list()\n",
        "\n",
        "for fraction in FRACTIONS:\n",
        "\n",
        "    model = AutoModelForSequenceClassification.from_pretrained('roberta-base', return_dict=True)\n",
        "    augmenter = MLMInsertionAugmenter(mlm_model, tokenizer, fraction, min_mask=1, topk=10, uniform=False, device=device)\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = get_datasets(\"sentiment140\", augmenter, train_size, val_size=1_000, test_size=20_000, augmentation_prob=AUGMENTATION_PROB)\n",
        "    print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}, Test size: {len(test_dataset)}\")\n",
        "    print(f\"Augmentation fraction: {fraction}\")\n",
        "    print(train_dataset[0])\n",
        "    print(val_dataset[0])\n",
        "    print(test_dataset[0])\n",
        "    output_dir = os.path.join(ROOT_DIR, f\"train_size_{train_size}_p_{fraction}\")\n",
        "\n",
        "    num_train_epochs = 9\n",
        "\n",
        "    # https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments\n",
        "    training_args = TrainingArguments(\n",
        "        learning_rate=3e-5,\n",
        "        weight_decay=0.01,\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        per_device_train_batch_size=8,\n",
        "        per_device_eval_batch_size=8,\n",
        "        gradient_accumulation_steps=2,\n",
        "        warmup_steps=0,  # don't have any intuition for the right value here\n",
        "        logging_dir=output_dir,\n",
        "        logging_steps=5,\n",
        "        load_best_model_at_end=False,\n",
        "        evaluation_strategy='epoch',\n",
        "        remove_unused_columns=False,\n",
        "        no_cuda=False,\n",
        "        metric_for_best_model=\"eval_accuracy\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics\n",
        "        \n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    test_result = trainer.evaluate(test_dataset)\n",
        "\n",
        "    print(test_result)\n",
        "    accuracies.append(test_result['eval_accuracy'])\n",
        "\n",
        "\n",
        "    with open(os.path.join(output_dir, 'test_result.json'), 'w') as f:\n",
        "        json.dump(test_result, f, indent=4)\n",
        "\n",
        "    print()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Reusing dataset sentiment140 (/root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 100, Validation size: 1000, Test size: 20000\n",
            "Augmentation fraction: 0.0\n",
            "{'date': 'Mon May 04 06:28:55 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 4, 'text': \"2nd result of the day: found my timeout book of bars whiiich means i've now recovered everything I thought i'd lost. Small victories = \", 'user': 'Bandrew'}\n",
            "{'date': 'Wed Jun 24 23:21:53 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': \"yea!!!! I think I have someone to watch the dogs while we're away. just have to kennel for 2 days instead of 11. no one wanted Zhu \", 'user': 'lindentreephoto'}\n",
            "{'date': 'Sun Jun 07 07:43:33 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': 'why am i awake so early?  damn projects. super nervous for the science one. mines gunna be so lame i dont wanna fail ', 'user': '_stacey_rae'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 00:42, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.688572</td>\n",
              "      <td>0.691712</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.762655</td>\n",
              "      <td>0.690137</td>\n",
              "      <td>0.507000</td>\n",
              "      <td>0.672425</td>\n",
              "      <td>0.506507</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.738753</td>\n",
              "      <td>0.684074</td>\n",
              "      <td>0.515000</td>\n",
              "      <td>0.674715</td>\n",
              "      <td>0.510660</td>\n",
              "      <td>0.994071</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.716569</td>\n",
              "      <td>0.658528</td>\n",
              "      <td>0.569000</td>\n",
              "      <td>0.690151</td>\n",
              "      <td>0.542373</td>\n",
              "      <td>0.948617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.505957</td>\n",
              "      <td>0.600710</td>\n",
              "      <td>0.683000</td>\n",
              "      <td>0.717720</td>\n",
              "      <td>0.653160</td>\n",
              "      <td>0.796443</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.450586</td>\n",
              "      <td>0.561520</td>\n",
              "      <td>0.707000</td>\n",
              "      <td>0.703741</td>\n",
              "      <td>0.720497</td>\n",
              "      <td>0.687747</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.300618</td>\n",
              "      <td>0.593582</td>\n",
              "      <td>0.721000</td>\n",
              "      <td>0.749776</td>\n",
              "      <td>0.686371</td>\n",
              "      <td>0.826087</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.224942</td>\n",
              "      <td>0.555019</td>\n",
              "      <td>0.739000</td>\n",
              "      <td>0.741328</td>\n",
              "      <td>0.743539</td>\n",
              "      <td>0.739130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.171442</td>\n",
              "      <td>0.554884</td>\n",
              "      <td>0.748000</td>\n",
              "      <td>0.750495</td>\n",
              "      <td>0.751984</td>\n",
              "      <td>0.749012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5538463592529297, 'eval_accuracy': 0.7421, 'eval_f1': 0.7435616983195785, 'eval_precision': 0.7390058306156735, 'eval_recall': 0.7481740870435217, 'epoch': 8.923076923076923, 'total_flos': 26391296009760}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Reusing dataset sentiment140 (/root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-0296c87a11204350.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-3bcb3be70d144b41.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-608cbfda739612d2.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-2a35a668f5601000.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-04e6988834d57ee8.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-5d2f06d3ab50c47b.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 100, Validation size: 1000, Test size: 20000\n",
            "Augmentation fraction: 0.01\n",
            "{'date': 'Mon May 04 06:28:55 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 4, 'text': \"2nd result of the day: found back my timeout book of bars whiiich means i've now recovered everything I thought i'd lost. Small victories =\", 'user': 'Bandrew'}\n",
            "{'date': 'Wed Jun 24 23:21:53 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': \"yea!!!! I think I have someone to watch the dogs while we're away. just have to kennel for 2 days instead of 11. no one wanted Zhu \", 'user': 'lindentreephoto'}\n",
            "{'date': 'Sun Jun 07 07:43:33 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': 'why am i awake so early?  damn projects. super nervous for the science one. mines gunna be so lame i dont wanna fail ', 'user': '_stacey_rae'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 00:57, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.694149</td>\n",
              "      <td>0.692773</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.754219</td>\n",
              "      <td>0.687935</td>\n",
              "      <td>0.510000</td>\n",
              "      <td>0.673768</td>\n",
              "      <td>0.508032</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.752238</td>\n",
              "      <td>0.678012</td>\n",
              "      <td>0.609000</td>\n",
              "      <td>0.702209</td>\n",
              "      <td>0.571252</td>\n",
              "      <td>0.911067</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.737892</td>\n",
              "      <td>0.619520</td>\n",
              "      <td>0.687000</td>\n",
              "      <td>0.709917</td>\n",
              "      <td>0.668412</td>\n",
              "      <td>0.756917</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.457940</td>\n",
              "      <td>0.567644</td>\n",
              "      <td>0.703000</td>\n",
              "      <td>0.723721</td>\n",
              "      <td>0.683656</td>\n",
              "      <td>0.768775</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.430317</td>\n",
              "      <td>0.552540</td>\n",
              "      <td>0.718000</td>\n",
              "      <td>0.727273</td>\n",
              "      <td>0.712121</td>\n",
              "      <td>0.743083</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.289989</td>\n",
              "      <td>0.561525</td>\n",
              "      <td>0.730000</td>\n",
              "      <td>0.737864</td>\n",
              "      <td>0.725191</td>\n",
              "      <td>0.750988</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.224440</td>\n",
              "      <td>0.572502</td>\n",
              "      <td>0.736000</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.739130</td>\n",
              "      <td>0.739130</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.173368</td>\n",
              "      <td>0.581270</td>\n",
              "      <td>0.738000</td>\n",
              "      <td>0.748077</td>\n",
              "      <td>0.728464</td>\n",
              "      <td>0.768775</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5680694580078125, 'eval_accuracy': 0.7471, 'eval_f1': 0.7543467702768335, 'eval_precision': 0.7329872581406324, 'eval_recall': 0.7769884942471236, 'epoch': 8.923076923076923, 'total_flos': 26196846424560}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Reusing dataset sentiment140 (/root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-0296c87a11204350.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-3bcb3be70d144b41.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-608cbfda739612d2.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-2a35a668f5601000.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-04e6988834d57ee8.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-5d2f06d3ab50c47b.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 100, Validation size: 1000, Test size: 20000\n",
            "Augmentation fraction: 0.1\n",
            "{'date': 'Mon May 04 06:28:55 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 4, 'text': \"2nd result of the day: found my timeout book of bars whiiich that means i've now recovered everything I thought i'd lost. Small victories = )\", 'user': 'Bandrew'}\n",
            "{'date': 'Wed Jun 24 23:21:53 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': \"yea!!!! I think I have someone to watch the dogs while we're away. just have to kennel for 2 days instead of 11. no one wanted Zhu \", 'user': 'lindentreephoto'}\n",
            "{'date': 'Sun Jun 07 07:43:33 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': 'why am i awake so early?  damn projects. super nervous for the science one. mines gunna be so lame i dont wanna fail ', 'user': '_stacey_rae'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 00:59, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.709179</td>\n",
              "      <td>0.691316</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.768439</td>\n",
              "      <td>0.687730</td>\n",
              "      <td>0.516000</td>\n",
              "      <td>0.675603</td>\n",
              "      <td>0.511156</td>\n",
              "      <td>0.996047</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.762632</td>\n",
              "      <td>0.679208</td>\n",
              "      <td>0.586000</td>\n",
              "      <td>0.696925</td>\n",
              "      <td>0.553488</td>\n",
              "      <td>0.940711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.740407</td>\n",
              "      <td>0.644995</td>\n",
              "      <td>0.678000</td>\n",
              "      <td>0.614833</td>\n",
              "      <td>0.778788</td>\n",
              "      <td>0.507905</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.557707</td>\n",
              "      <td>0.587050</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.713494</td>\n",
              "      <td>0.670139</td>\n",
              "      <td>0.762846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.489175</td>\n",
              "      <td>0.547248</td>\n",
              "      <td>0.718000</td>\n",
              "      <td>0.729885</td>\n",
              "      <td>0.708178</td>\n",
              "      <td>0.752964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.303142</td>\n",
              "      <td>0.543860</td>\n",
              "      <td>0.729000</td>\n",
              "      <td>0.740173</td>\n",
              "      <td>0.718808</td>\n",
              "      <td>0.762846</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.245081</td>\n",
              "      <td>0.557314</td>\n",
              "      <td>0.741000</td>\n",
              "      <td>0.752627</td>\n",
              "      <td>0.728281</td>\n",
              "      <td>0.778656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.171062</td>\n",
              "      <td>0.562349</td>\n",
              "      <td>0.746000</td>\n",
              "      <td>0.754826</td>\n",
              "      <td>0.737736</td>\n",
              "      <td>0.772727</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5483174920082092, 'eval_accuracy': 0.7557, 'eval_f1': 0.763550135501355, 'eval_precision': 0.739431999250164, 'eval_recall': 0.7892946473236618, 'epoch': 8.923076923076923, 'total_flos': 26618652447840}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Reusing dataset sentiment140 (/root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-0296c87a11204350.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-3bcb3be70d144b41.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-608cbfda739612d2.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-2a35a668f5601000.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-04e6988834d57ee8.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-5d2f06d3ab50c47b.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 100, Validation size: 1000, Test size: 20000\n",
            "Augmentation fraction: 0.15\n",
            "{'date': 'Mon May 04 06:28:55 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 4, 'text': \"2nd positive result of the day: found my timeout book of bars whiiich means i've just now recovered everything I really thought i'd lost. Small victories =\", 'user': 'Bandrew'}\n",
            "{'date': 'Wed Jun 24 23:21:53 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': \"yea!!!! I think I have someone to watch the dogs while we're away. just have to kennel for 2 days instead of 11. no one wanted Zhu \", 'user': 'lindentreephoto'}\n",
            "{'date': 'Sun Jun 07 07:43:33 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': 'why am i awake so early?  damn projects. super nervous for the science one. mines gunna be so lame i dont wanna fail ', 'user': '_stacey_rae'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 01:01, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.691943</td>\n",
              "      <td>0.694359</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.761340</td>\n",
              "      <td>0.691869</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.758989</td>\n",
              "      <td>0.687686</td>\n",
              "      <td>0.508000</td>\n",
              "      <td>0.672872</td>\n",
              "      <td>0.507014</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.738916</td>\n",
              "      <td>0.669779</td>\n",
              "      <td>0.664000</td>\n",
              "      <td>0.654321</td>\n",
              "      <td>0.682403</td>\n",
              "      <td>0.628458</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.618284</td>\n",
              "      <td>0.616685</td>\n",
              "      <td>0.692000</td>\n",
              "      <td>0.701550</td>\n",
              "      <td>0.688213</td>\n",
              "      <td>0.715415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.576496</td>\n",
              "      <td>0.560397</td>\n",
              "      <td>0.719000</td>\n",
              "      <td>0.720398</td>\n",
              "      <td>0.725451</td>\n",
              "      <td>0.715415</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.421740</td>\n",
              "      <td>0.548072</td>\n",
              "      <td>0.727000</td>\n",
              "      <td>0.747922</td>\n",
              "      <td>0.701906</td>\n",
              "      <td>0.800395</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.350708</td>\n",
              "      <td>0.533772</td>\n",
              "      <td>0.740000</td>\n",
              "      <td>0.747573</td>\n",
              "      <td>0.734733</td>\n",
              "      <td>0.760870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.286944</td>\n",
              "      <td>0.533870</td>\n",
              "      <td>0.752000</td>\n",
              "      <td>0.761538</td>\n",
              "      <td>0.741573</td>\n",
              "      <td>0.782609</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.518985390663147, 'eval_accuracy': 0.75265, 'eval_f1': 0.7591176900228854, 'eval_precision': 0.7394232593435781, 'eval_recall': 0.7798899449724862, 'epoch': 8.923076923076923, 'total_flos': 27061399195680}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Reusing dataset sentiment140 (/root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-0296c87a11204350.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-3bcb3be70d144b41.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-608cbfda739612d2.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-2a35a668f5601000.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-04e6988834d57ee8.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-5d2f06d3ab50c47b.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 100, Validation size: 1000, Test size: 20000\n",
            "Augmentation fraction: 0.2\n",
            "{'date': 'Mon May 04 06:28:55 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 4, 'text': \"2nd major result of saving the day: found my timeout book instead of bars whiiich means i've now recovered everything I thought i'd lost. - Small victories =\", 'user': 'Bandrew'}\n",
            "{'date': 'Wed Jun 24 23:21:53 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': \"yea!!!! I think I have someone to watch the dogs while we're away. just have to kennel for 2 days instead of 11. no one wanted Zhu \", 'user': 'lindentreephoto'}\n",
            "{'date': 'Sun Jun 07 07:43:33 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': 'why am i awake so early?  damn projects. super nervous for the science one. mines gunna be so lame i dont wanna fail ', 'user': '_stacey_rae'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 01:05, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.700842</td>\n",
              "      <td>0.692921</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.761220</td>\n",
              "      <td>0.692347</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.750940</td>\n",
              "      <td>0.686710</td>\n",
              "      <td>0.508000</td>\n",
              "      <td>0.672872</td>\n",
              "      <td>0.507014</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.737152</td>\n",
              "      <td>0.661624</td>\n",
              "      <td>0.656000</td>\n",
              "      <td>0.663405</td>\n",
              "      <td>0.656977</td>\n",
              "      <td>0.669960</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.571026</td>\n",
              "      <td>0.626051</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.706406</td>\n",
              "      <td>0.642395</td>\n",
              "      <td>0.784585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.584306</td>\n",
              "      <td>0.608373</td>\n",
              "      <td>0.683000</td>\n",
              "      <td>0.647386</td>\n",
              "      <td>0.740458</td>\n",
              "      <td>0.575099</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.475239</td>\n",
              "      <td>0.601359</td>\n",
              "      <td>0.690000</td>\n",
              "      <td>0.712430</td>\n",
              "      <td>0.671329</td>\n",
              "      <td>0.758893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.413077</td>\n",
              "      <td>0.592718</td>\n",
              "      <td>0.692000</td>\n",
              "      <td>0.696252</td>\n",
              "      <td>0.694882</td>\n",
              "      <td>0.697628</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.355839</td>\n",
              "      <td>0.591746</td>\n",
              "      <td>0.694000</td>\n",
              "      <td>0.697628</td>\n",
              "      <td>0.697628</td>\n",
              "      <td>0.697628</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5830125212669373, 'eval_accuracy': 0.7131, 'eval_f1': 0.714470541401274, 'eval_precision': 0.7107217107217108, 'eval_recall': 0.7182591295647824, 'epoch': 8.923076923076923, 'total_flos': 27560985053040}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Reusing dataset sentiment140 (/root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-0296c87a11204350.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-3bcb3be70d144b41.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-608cbfda739612d2.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-2a35a668f5601000.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-04e6988834d57ee8.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-5d2f06d3ab50c47b.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 100, Validation size: 1000, Test size: 20000\n",
            "Augmentation fraction: 0.25\n",
            "{'date': 'Mon May 04 06:28:55 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 4, 'text': \"2nd result of the the day: found my timeout little book of bars whiiich means that i've just now recovered everything I thought i'd lost. Small victories . = D\", 'user': 'Bandrew'}\n",
            "{'date': 'Wed Jun 24 23:21:53 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': \"yea!!!! I think I have someone to watch the dogs while we're away. just have to kennel for 2 days instead of 11. no one wanted Zhu \", 'user': 'lindentreephoto'}\n",
            "{'date': 'Sun Jun 07 07:43:33 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': 'why am i awake so early?  damn projects. super nervous for the science one. mines gunna be so lame i dont wanna fail ', 'user': '_stacey_rae'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 01:09, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.701543</td>\n",
              "      <td>0.697547</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.765588</td>\n",
              "      <td>0.694566</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.747124</td>\n",
              "      <td>0.683099</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.719148</td>\n",
              "      <td>0.625574</td>\n",
              "      <td>0.666000</td>\n",
              "      <td>0.705467</td>\n",
              "      <td>0.636943</td>\n",
              "      <td>0.790514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.461905</td>\n",
              "      <td>0.588709</td>\n",
              "      <td>0.680000</td>\n",
              "      <td>0.718310</td>\n",
              "      <td>0.647619</td>\n",
              "      <td>0.806324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.381504</td>\n",
              "      <td>0.570167</td>\n",
              "      <td>0.714000</td>\n",
              "      <td>0.725000</td>\n",
              "      <td>0.705993</td>\n",
              "      <td>0.745059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.249905</td>\n",
              "      <td>0.658697</td>\n",
              "      <td>0.710000</td>\n",
              "      <td>0.746946</td>\n",
              "      <td>0.668750</td>\n",
              "      <td>0.845850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.217424</td>\n",
              "      <td>0.609848</td>\n",
              "      <td>0.719000</td>\n",
              "      <td>0.731100</td>\n",
              "      <td>0.708720</td>\n",
              "      <td>0.754941</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.172892</td>\n",
              "      <td>0.614806</td>\n",
              "      <td>0.736000</td>\n",
              "      <td>0.748571</td>\n",
              "      <td>0.722426</td>\n",
              "      <td>0.776680</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6251196265220642, 'eval_accuracy': 0.7348, 'eval_f1': 0.7466080642079114, 'eval_precision': 0.7144555179665356, 'eval_recall': 0.7817908954477238, 'epoch': 8.923076923076923, 'total_flos': 28243054367280}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Reusing dataset sentiment140 (/root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-0296c87a11204350.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-3bcb3be70d144b41.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-608cbfda739612d2.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-2a35a668f5601000.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-04e6988834d57ee8.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-5d2f06d3ab50c47b.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 100, Validation size: 1000, Test size: 20000\n",
            "Augmentation fraction: 0.3\n",
            "{'date': 'Mon May 04 06:28:55 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 4, 'text': \"2nd result of the day: found my timeout book full of bars , whiiich means that i've now recovered everything that I 'd thought that i'd completely lost. Small victories =\", 'user': 'Bandrew'}\n",
            "{'date': 'Wed Jun 24 23:21:53 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': \"yea!!!! I think I have someone to watch the dogs while we're away. just have to kennel for 2 days instead of 11. no one wanted Zhu \", 'user': 'lindentreephoto'}\n",
            "{'date': 'Sun Jun 07 07:43:33 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': 'why am i awake so early?  damn projects. super nervous for the science one. mines gunna be so lame i dont wanna fail ', 'user': '_stacey_rae'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 01:11, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.697012</td>\n",
              "      <td>0.696674</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.767754</td>\n",
              "      <td>0.696263</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.766550</td>\n",
              "      <td>0.690993</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.740667</td>\n",
              "      <td>0.678466</td>\n",
              "      <td>0.543000</td>\n",
              "      <td>0.680196</td>\n",
              "      <td>0.526544</td>\n",
              "      <td>0.960474</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.642934</td>\n",
              "      <td>0.657928</td>\n",
              "      <td>0.620000</td>\n",
              "      <td>0.703125</td>\n",
              "      <td>0.581395</td>\n",
              "      <td>0.889328</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.652968</td>\n",
              "      <td>0.612650</td>\n",
              "      <td>0.688000</td>\n",
              "      <td>0.717902</td>\n",
              "      <td>0.661667</td>\n",
              "      <td>0.784585</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.517936</td>\n",
              "      <td>0.587015</td>\n",
              "      <td>0.684000</td>\n",
              "      <td>0.714286</td>\n",
              "      <td>0.658333</td>\n",
              "      <td>0.780632</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.423005</td>\n",
              "      <td>0.569153</td>\n",
              "      <td>0.697000</td>\n",
              "      <td>0.714420</td>\n",
              "      <td>0.682883</td>\n",
              "      <td>0.749012</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.376355</td>\n",
              "      <td>0.568730</td>\n",
              "      <td>0.702000</td>\n",
              "      <td>0.717803</td>\n",
              "      <td>0.689091</td>\n",
              "      <td>0.749012</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5746767520904541, 'eval_accuracy': 0.71735, 'eval_f1': 0.7331602548973329, 'eval_precision': 0.6940125111706881, 'eval_recall': 0.7769884942471236, 'epoch': 8.923076923076923, 'total_flos': 28832386187040}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Reusing dataset sentiment140 (/root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-0296c87a11204350.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-3bcb3be70d144b41.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-608cbfda739612d2.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-2a35a668f5601000.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-04e6988834d57ee8.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-5d2f06d3ab50c47b.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 100, Validation size: 1000, Test size: 20000\n",
            "Augmentation fraction: 0.4\n",
            "{'date': 'Mon May 04 06:28:55 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 4, 'text': \"2nd result find of the day: found my second timeout book of bars yesterday , whiiich means i've now sort % recovered from everything I thought that i'd lost. Small er victories =\", 'user': 'Bandrew'}\n",
            "{'date': 'Wed Jun 24 23:21:53 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': \"yea!!!! I think I have someone to watch the dogs while we're away. just have to kennel for 2 days instead of 11. no one wanted Zhu \", 'user': 'lindentreephoto'}\n",
            "{'date': 'Sun Jun 07 07:43:33 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': 'why am i awake so early?  damn projects. super nervous for the science one. mines gunna be so lame i dont wanna fail ', 'user': '_stacey_rae'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 01:19, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.701469</td>\n",
              "      <td>0.691924</td>\n",
              "      <td>0.524000</td>\n",
              "      <td>0.677069</td>\n",
              "      <td>0.515496</td>\n",
              "      <td>0.986166</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.753766</td>\n",
              "      <td>0.688741</td>\n",
              "      <td>0.590000</td>\n",
              "      <td>0.678683</td>\n",
              "      <td>0.562338</td>\n",
              "      <td>0.855731</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.769194</td>\n",
              "      <td>0.686191</td>\n",
              "      <td>0.576000</td>\n",
              "      <td>0.693642</td>\n",
              "      <td>0.546697</td>\n",
              "      <td>0.948617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.764473</td>\n",
              "      <td>0.682085</td>\n",
              "      <td>0.602000</td>\n",
              "      <td>0.690031</td>\n",
              "      <td>0.569409</td>\n",
              "      <td>0.875494</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.650256</td>\n",
              "      <td>0.675341</td>\n",
              "      <td>0.609000</td>\n",
              "      <td>0.705350</td>\n",
              "      <td>0.570037</td>\n",
              "      <td>0.924901</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.715660</td>\n",
              "      <td>0.658746</td>\n",
              "      <td>0.679000</td>\n",
              "      <td>0.703601</td>\n",
              "      <td>0.660312</td>\n",
              "      <td>0.752964</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.687245</td>\n",
              "      <td>0.637343</td>\n",
              "      <td>0.704000</td>\n",
              "      <td>0.692946</td>\n",
              "      <td>0.729258</td>\n",
              "      <td>0.660079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.622557</td>\n",
              "      <td>0.616876</td>\n",
              "      <td>0.712000</td>\n",
              "      <td>0.698745</td>\n",
              "      <td>0.742222</td>\n",
              "      <td>0.660079</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.620369</td>\n",
              "      <td>0.606795</td>\n",
              "      <td>0.721000</td>\n",
              "      <td>0.710881</td>\n",
              "      <td>0.747277</td>\n",
              "      <td>0.677866</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:05]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.6045017242431641, 'eval_accuracy': 0.7195, 'eval_f1': 0.6996144784750482, 'eval_precision': 0.752563068770879, 'eval_recall': 0.6536268134067034, 'epoch': 8.923076923076923, 'total_flos': 30169601026800}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Reusing dataset sentiment140 (/root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-0296c87a11204350.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-3bcb3be70d144b41.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-608cbfda739612d2.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-2a35a668f5601000.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-04e6988834d57ee8.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-5d2f06d3ab50c47b.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 100, Validation size: 1000, Test size: 20000\n",
            "Augmentation fraction: 0.5\n",
            "{'date': 'Mon May 04 06:28:55 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 4, 'text': \"My My 2nd greatest result as of course the day: found my first timeout in the book of bars , whiiich means i've now recovered from everything I thought i'd already lost. Small victories : =\", 'user': 'Bandrew'}\n",
            "{'date': 'Wed Jun 24 23:21:53 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': \"yea!!!! I think I have someone to watch the dogs while we're away. just have to kennel for 2 days instead of 11. no one wanted Zhu \", 'user': 'lindentreephoto'}\n",
            "{'date': 'Sun Jun 07 07:43:33 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': 'why am i awake so early?  damn projects. super nervous for the science one. mines gunna be so lame i dont wanna fail ', 'user': '_stacey_rae'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 01:27, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.706284</td>\n",
              "      <td>0.692577</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.765905</td>\n",
              "      <td>0.691216</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.747553</td>\n",
              "      <td>0.687599</td>\n",
              "      <td>0.507000</td>\n",
              "      <td>0.672425</td>\n",
              "      <td>0.506507</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.746544</td>\n",
              "      <td>0.678131</td>\n",
              "      <td>0.647000</td>\n",
              "      <td>0.685663</td>\n",
              "      <td>0.623987</td>\n",
              "      <td>0.760870</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.646966</td>\n",
              "      <td>0.661281</td>\n",
              "      <td>0.688000</td>\n",
              "      <td>0.683570</td>\n",
              "      <td>0.702083</td>\n",
              "      <td>0.666008</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.662088</td>\n",
              "      <td>0.628105</td>\n",
              "      <td>0.714000</td>\n",
              "      <td>0.694444</td>\n",
              "      <td>0.755814</td>\n",
              "      <td>0.642292</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.622605</td>\n",
              "      <td>0.616457</td>\n",
              "      <td>0.670000</td>\n",
              "      <td>0.721754</td>\n",
              "      <td>0.629412</td>\n",
              "      <td>0.845850</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.563271</td>\n",
              "      <td>0.583208</td>\n",
              "      <td>0.703000</td>\n",
              "      <td>0.717949</td>\n",
              "      <td>0.691042</td>\n",
              "      <td>0.747036</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.524231</td>\n",
              "      <td>0.573849</td>\n",
              "      <td>0.718000</td>\n",
              "      <td>0.720792</td>\n",
              "      <td>0.722222</td>\n",
              "      <td>0.719368</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5703228712081909, 'eval_accuracy': 0.7193, 'eval_f1': 0.7230936174410575, 'eval_precision': 0.7131043875863411, 'eval_recall': 0.7333666833416709, 'epoch': 8.923076923076923, 'total_flos': 31602544893120}\n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Reusing dataset sentiment140 (/root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-0296c87a11204350.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-3bcb3be70d144b41.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-608cbfda739612d2.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-2a35a668f5601000.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-04e6988834d57ee8.arrow and /root/.cache/huggingface/datasets/sentiment140/sentiment140/1.0.0/9fe1c0ce3319c47cc65ff7e49aac6c34d9c050ab1432988c104b3b275e360f3f/cache-5d2f06d3ab50c47b.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 100, Validation size: 1000, Test size: 20000\n",
            "Augmentation fraction: 0.6\n",
            "{'date': 'Mon May 04 06:28:55 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 4, 'text': \"2nd result of the day: found my timeout book of bars whiiich means i've now recovered everything I thought i'd lost. Small victories = \", 'user': 'Bandrew'}\n",
            "{'date': 'Wed Jun 24 23:21:53 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': \"yea!!!! I think I have someone to watch the dogs while we're away. just have to kennel for 2 days instead of 11. no one wanted Zhu \", 'user': 'lindentreephoto'}\n",
            "{'date': 'Sun Jun 07 07:43:33 PDT 2009', 'query': 'NO_QUERY', 'sentiment': 0, 'text': 'why am i awake so early?  damn projects. super nervous for the science one. mines gunna be so lame i dont wanna fail ', 'user': '_stacey_rae'}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='54' max='54' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [54/54 01:35, Epoch 8/9]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "      <th>Precision</th>\n",
              "      <th>Recall</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>0</td>\n",
              "      <td>0.699085</td>\n",
              "      <td>0.697672</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.772871</td>\n",
              "      <td>0.693380</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>0.671979</td>\n",
              "      <td>0.506000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.793959</td>\n",
              "      <td>0.689596</td>\n",
              "      <td>0.507000</td>\n",
              "      <td>0.672425</td>\n",
              "      <td>0.506507</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.738652</td>\n",
              "      <td>0.685885</td>\n",
              "      <td>0.539000</td>\n",
              "      <td>0.682725</td>\n",
              "      <td>0.523759</td>\n",
              "      <td>0.980237</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.666360</td>\n",
              "      <td>0.678137</td>\n",
              "      <td>0.573000</td>\n",
              "      <td>0.692141</td>\n",
              "      <td>0.544835</td>\n",
              "      <td>0.948617</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.710661</td>\n",
              "      <td>0.659776</td>\n",
              "      <td>0.658000</td>\n",
              "      <td>0.704663</td>\n",
              "      <td>0.625767</td>\n",
              "      <td>0.806324</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.666724</td>\n",
              "      <td>0.637116</td>\n",
              "      <td>0.655000</td>\n",
              "      <td>0.716049</td>\n",
              "      <td>0.613540</td>\n",
              "      <td>0.859684</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.612968</td>\n",
              "      <td>0.611571</td>\n",
              "      <td>0.664000</td>\n",
              "      <td>0.716216</td>\n",
              "      <td>0.625369</td>\n",
              "      <td>0.837945</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>8</td>\n",
              "      <td>0.573511</td>\n",
              "      <td>0.597496</td>\n",
              "      <td>0.681000</td>\n",
              "      <td>0.720421</td>\n",
              "      <td>0.647244</td>\n",
              "      <td>0.812253</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='2500' max='2500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [2500/2500 01:04]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.5979194045066833, 'eval_accuracy': 0.69195, 'eval_f1': 0.7294840834248079, 'eval_precision': 0.65, 'eval_recall': 0.8311155577788895, 'epoch': 8.923076923076923, 'total_flos': 32841039174240}\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MsCZIjgGGZfm",
        "outputId": "fd7ad701-666c-4ef1-8dcf-c636b452c5da",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "plt.plot(FRACTIONS, accuracies)\n",
        "plt.scatter(FRACTIONS, accuracies)\n",
        "plt.title('Twitter')\n",
        "plt.xlabel('Augmentation strength')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.savefig(os.path.join(ROOT_DIR, 'twitter_1000_mlm_insertion_strength.eps'), format='eps', bbox_inches='tight')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}