{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ag_news_mlm_insertion_strength.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dqp4A6lcASV6"
      },
      "source": [
        "# AG News: MLM Insertion"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sWtJcEfMpygI",
        "outputId": "97c09ae0-8c1a-40e9-a76d-65faa297c868",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import json\n",
        "import heapq\n",
        "import os\n",
        "import random\n",
        "from typing import List\n",
        "\n",
        "%pip install -U datasets\n",
        "%pip install transformers\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import torch\n",
        "from datasets import load_dataset\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "from torch.utils.data import DataLoader\n",
        "from transformers import AutoModelForMaskedLM, AutoModelForSequenceClassification, AutoTokenizer, Trainer, TrainingArguments\n",
        "\n",
        "\n",
        "plt.style.use('fivethirtyeight')\n",
        "\n",
        "ROOT_DIR = \"drive/My Drive/Colab Notebooks/nlp/results/twitter_mlm_insertion\"\n",
        "if not os.path.exists(ROOT_DIR):\n",
        "    os.mkdir(ROOT_DIR)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already up-to-date: datasets in /usr/local/lib/python3.6/dist-packages (1.1.2)\n",
            "Requirement already satisfied, skipping upgrade: multiprocess in /usr/local/lib/python3.6/dist-packages (from datasets) (0.70.10)\n",
            "Requirement already satisfied, skipping upgrade: requests>=2.19.0 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.23.0)\n",
            "Requirement already satisfied, skipping upgrade: xxhash in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from datasets) (3.0.12)\n",
            "Requirement already satisfied, skipping upgrade: dill in /usr/local/lib/python3.6/dist-packages (from datasets) (0.3.3)\n",
            "Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from datasets) (0.7)\n",
            "Requirement already satisfied, skipping upgrade: pyarrow>=0.17.1 in /usr/local/lib/python3.6/dist-packages (from datasets) (2.0.0)\n",
            "Requirement already satisfied, skipping upgrade: pandas in /usr/local/lib/python3.6/dist-packages (from datasets) (1.1.4)\n",
            "Requirement already satisfied, skipping upgrade: tqdm<4.50.0,>=4.27 in /usr/local/lib/python3.6/dist-packages (from datasets) (4.41.1)\n",
            "Requirement already satisfied, skipping upgrade: numpy>=1.17 in /usr/local/lib/python3.6/dist-packages (from datasets) (1.18.5)\n",
            "Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2.10)\n",
            "Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (1.24.3)\n",
            "Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (3.0.4)\n",
            "Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.19.0->datasets) (2020.6.20)\n",
            "Requirement already satisfied, skipping upgrade: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2018.9)\n",
            "Requirement already satisfied, skipping upgrade: python-dateutil>=2.7.3 in /usr/local/lib/python3.6/dist-packages (from pandas->datasets) (2.8.1)\n",
            "Requirement already satisfied, skipping upgrade: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.7.3->pandas->datasets) (1.15.0)\n",
            "Requirement already satisfied: transformers in /usr/local/lib/python3.6/dist-packages (3.4.0)\n",
            "Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.1.94)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Requirement already satisfied: tokenizers==0.9.2 in /usr/local/lib/python3.6/dist-packages (from transformers) (0.9.2)\n",
            "Requirement already satisfied: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers) (0.0.43)\n",
            "Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BZW4JvsPxhff"
      },
      "source": [
        "## Defining augmentation function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u9a5MnCnxkNO"
      },
      "source": [
        "class MLMInsertionAugmenter:\n",
        "    def __init__(self, model, tokenizer, p: float, min_mask: int = 1, topk: int = 5, uniform: bool = False, device=None):\n",
        "        self.model = model.eval()\n",
        "        self.tokenizer = tokenizer\n",
        "        self.vocab_words = list(tokenizer.get_vocab().keys())\n",
        "        self.mask_token = tokenizer.mask_token\n",
        "        self.mask_token_id = tokenizer.mask_token_id\n",
        "        self.topk = topk\n",
        "        self.min_mask = min_mask\n",
        "        self.uniform = uniform\n",
        "        self.p = p\n",
        "        self.device = device or torch.device('cpu')\n",
        "        \n",
        "    def __call__(self, text: str):\n",
        "        words = np.array(text.split(), dtype='object')\n",
        "        n_mask = max(self.min_mask, int(len(words) * self.p))\n",
        "        masked_indices = np.sort(np.random.choice(len(words) + 1, size=n_mask))\n",
        "\n",
        "        masked_words = np.insert(words, masked_indices, self.mask_token)\n",
        "        masked_text = \" \".join(masked_words)\n",
        "        \n",
        "        tokenizer_output = self.tokenizer([masked_text])\n",
        "        input_ids = torch.tensor(tokenizer_output['input_ids']).to(self.device)\n",
        "        attention_mask = torch.tensor(tokenizer_output['attention_mask']).to(self.device)\n",
        "        with torch.no_grad():\n",
        "            output = self.model(input_ids)\n",
        "            predicted_logits = output.logits[input_ids == self.mask_token_id]\n",
        "            predicted_probas = predicted_logits.softmax(1)\n",
        "            \n",
        "        predicted_words = [self.sample_word(probas).strip() for probas in predicted_probas]\n",
        "        \n",
        "        new_words = np.insert(words, masked_indices, predicted_words)\n",
        "        new_text = \" \".join(new_words)\n",
        "        return new_text\n",
        "    \n",
        "    \n",
        "    def sample_word(self, predicted_probas):\n",
        "        if hasattr(predicted_probas, 'tolist'):\n",
        "            predicted_probas = predicted_probas.tolist()\n",
        "        most_probable = heapq.nlargest(self.topk, zip(self.vocab_words, predicted_probas), key=lambda t: t[1])\n",
        "        words, probas = zip(*most_probable)\n",
        "        word = random.choice(words) if self.uniform else random.choices(words, weights=probas)[0]\n",
        "        return self.tokenizer.convert_tokens_to_string(word).strip()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vEFFI0Kdp4k6"
      },
      "source": [
        "class DatasetWithAugmentation(torch.utils.data.Dataset):\n",
        "    def __init__(self, dataset, augmenter, augmentation_prob: float = 0.9):\n",
        "        self.dataset = dataset\n",
        "        self.augmenter = augmenter\n",
        "        self.augmentation_prob = augmentation_prob\n",
        "\n",
        "    def __getitem__(self, i):\n",
        "        item = self.dataset[i]\n",
        "        if random.random() < self.augmentation_prob:\n",
        "            item['text'] = self.augmenter(item['text'])\n",
        "        return item\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.dataset)\n",
        "\n",
        "\n",
        "def get_datasets(dataset_name, augmenter, train_size, val_size=5_000, test_size=None, augmentation_prob=0.5, random_seed: int = 42):\n",
        "    \"\"\"Returns \"\"\"\n",
        "    dataset = load_dataset(dataset_name, split=\"train\")\n",
        "    test_dataset = load_dataset(dataset_name, split=\"test\")\n",
        "    # We want test and validation data to be the same for every experiment\n",
        "    if test_size:\n",
        "        test_dataset = test_dataset.train_test_split(test_size=test_size, seed=random_seed)[\"test\"]\n",
        "    train_val_split = dataset.train_test_split(test_size=val_size, seed=random_seed)\n",
        "    # Validation and test sets\n",
        "    train_dataset = train_val_split[\"train\"].train_test_split(train_size=train_size, seed=random_seed)[\"train\"]\n",
        "    train_dataset = DatasetWithAugmentation(train_dataset, augmenter, augmentation_prob=augmentation_prob)\n",
        "    val_dataset = train_val_split[\"test\"]\n",
        "    return train_dataset, val_dataset, test_dataset\n",
        "\n",
        "\n",
        "class DataCollator:\n",
        "    def __init__(self, tokenizer):\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "    def __call__(self, examples: List[dict]):\n",
        "        labels = [example['label'] for example in examples]\n",
        "        texts = [example['text'] for example in examples]\n",
        "        tokenizer_output = self.tokenizer(texts, truncation=True, padding=True)\n",
        "        return {\n",
        "            'labels': torch.tensor(labels), \n",
        "            'input_ids': torch.tensor(tokenizer_output['input_ids']), \n",
        "            'attention_mask': torch.tensor(tokenizer_output['attention_mask'])\n",
        "            }\n",
        "\n",
        "\n",
        "def compute_metrics(pred):\n",
        "    labels = pred.label_ids\n",
        "    preds = pred.predictions.argmax(-1)\n",
        "    precision, recall, micro_f1, _ = precision_recall_fscore_support(labels, preds, average='micro', zero_division=0)\n",
        "    _, _, macro_f1, _ = precision_recall_fscore_support(labels, preds, average='macro', zero_division=0)\n",
        "    acc = accuracy_score(labels, preds)\n",
        "    return {\n",
        "        'accuracy': acc,\n",
        "        'micro_f1': micro_f1,\n",
        "        'micro_precision': precision,\n",
        "        'micro_recall': recall,\n",
        "        'macro_f1': macro_f1\n",
        "    }"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sW2d5HGCqTTb",
        "outputId": "ee0f4bef-b19e-4a6e-f8cd-5e05b7ae8cca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "AUGMENTATION_PROB = 0.5\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('roberta-base', use_fast=False)  # we cannot use Fast tokenizer for MLMInsertionAugmenter\n",
        "data_collator = DataCollator(tokenizer)\n",
        "\n",
        "device = torch.device('cuda')\n",
        "mlm_model = AutoModelForMaskedLM.from_pretrained('roberta-base', return_dict=True).eval().to(device)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of RobertaForMaskedLM were not initialized from the model checkpoint at roberta-base and are newly initialized: ['lm_head.decoder.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hwhkqPjlI35c"
      },
      "source": [
        "augmenter = MLMInsertionAugmenter(mlm_model, tokenizer, 0.2, min_mask=1, topk=10, uniform=False, device=device)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J4DcM5uNI5kb",
        "outputId": "f06efc70-4c0b-4f9f-8a0d-4bfcc7fe3df2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "augmenter('I love you')"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'I love seeing you'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ld0FI0F7qhMm",
        "outputId": "7f75cd98-b756-4184-e96c-cbbf91a6f98b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "train_size = 1000\n",
        "\n",
        "FRACTIONS = [0.01, 0.1, 0.15, 0.2, 0.25, 0.3, 0.4, 0.5, 0.6, 0.7]\n",
        "accuracies = list()\n",
        "\n",
        "for fraction in FRACTIONS:\n",
        "    model = AutoModelForSequenceClassification.from_pretrained('roberta-base', return_dict=True, num_labels=4)\n",
        "    augmenter = MLMInsertionAugmenter(mlm_model, tokenizer, fraction, min_mask=1, topk=10, uniform=False, device=device)\n",
        "\n",
        "    train_dataset, val_dataset, test_dataset = get_datasets(\"ag_news\", augmenter, train_size, val_size=5_000, augmentation_prob=AUGMENTATION_PROB)\n",
        "    print(f\"Train size: {len(train_dataset)}, Validation size: {len(val_dataset)}, Test size: {len(test_dataset)}\")\n",
        "    print(f\"Augmentation fraction: {fraction}\")\n",
        "    print(train_dataset[0])\n",
        "    print(val_dataset[0])\n",
        "    print(test_dataset[0])\n",
        "    output_dir = os.path.join(ROOT_DIR, f\"train_size_{train_size}_augmentation_fraction_{fraction}\")\n",
        "\n",
        "    num_train_epochs = 7\n",
        "\n",
        "    # https://huggingface.co/transformers/main_classes/trainer.html#trainingarguments\n",
        "    training_args = TrainingArguments(\n",
        "        learning_rate=3e-5,\n",
        "        weight_decay=0.01,\n",
        "        output_dir=output_dir,\n",
        "        num_train_epochs=num_train_epochs,\n",
        "        per_device_train_batch_size=16,\n",
        "        per_device_eval_batch_size=16,\n",
        "        warmup_steps=0,  # don't have any intuition for the right value here\n",
        "        logging_dir=output_dir,\n",
        "        logging_steps=32,\n",
        "        load_best_model_at_end=True,\n",
        "        evaluation_strategy='epoch',\n",
        "        remove_unused_columns=False,\n",
        "        no_cuda=False,\n",
        "        metric_for_best_model=\"eval_accuracy\"\n",
        "    )\n",
        "\n",
        "    trainer = Trainer(\n",
        "        model=model,\n",
        "        args=training_args,\n",
        "        train_dataset=train_dataset,\n",
        "        eval_dataset=val_dataset,\n",
        "        data_collator=data_collator,\n",
        "        compute_metrics=compute_metrics\n",
        "        \n",
        "    )\n",
        "\n",
        "    trainer.train()\n",
        "\n",
        "    test_result = trainer.evaluate(test_dataset)\n",
        "    \n",
        "\n",
        "    print(test_result)\n",
        "    accuracies.append(test_result['eval_accuracy'])\n",
        "\n",
        "    with open(os.path.join(output_dir, 'test_result.json'), 'w') as f:\n",
        "        json.dump(test_result, f, indent=4)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-92772b76e88bb499.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-8ed9880a16a40baf.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-a3f671cb248fccca.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-f3fb7572504c893f.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 1000, Validation size: 5000, Test size: 7600\n",
            "Augmentation fraction: 0.01\n",
            "{'label': 3, 'text': 'Study: High-tech firms praised for online customer respect While many high-tech firms scored well in a new study of how they treat customers online, more than a third of the surveyed companies still share personal data without permission. </s>'}\n",
            "{'label': 0, 'text': 'Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.'}\n",
            "{'label': 2, 'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='441' max='441' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [441/441 08:32, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.020148</td>\n",
              "      <td>0.338581</td>\n",
              "      <td>0.892400</td>\n",
              "      <td>0.892400</td>\n",
              "      <td>0.892400</td>\n",
              "      <td>0.892400</td>\n",
              "      <td>0.891374</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.272019</td>\n",
              "      <td>0.379621</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.896810</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.167371</td>\n",
              "      <td>0.458887</td>\n",
              "      <td>0.890600</td>\n",
              "      <td>0.890600</td>\n",
              "      <td>0.890600</td>\n",
              "      <td>0.890600</td>\n",
              "      <td>0.888541</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.115211</td>\n",
              "      <td>0.433138</td>\n",
              "      <td>0.902800</td>\n",
              "      <td>0.902800</td>\n",
              "      <td>0.902800</td>\n",
              "      <td>0.902800</td>\n",
              "      <td>0.901655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.090819</td>\n",
              "      <td>0.525124</td>\n",
              "      <td>0.897600</td>\n",
              "      <td>0.897600</td>\n",
              "      <td>0.897600</td>\n",
              "      <td>0.897600</td>\n",
              "      <td>0.896893</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.032462</td>\n",
              "      <td>0.533387</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.895812</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.030292</td>\n",
              "      <td>0.539328</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.895797</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [475/475 00:40]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4384109675884247, 'eval_accuracy': 0.8990789473684211, 'eval_micro_f1': 0.8990789473684211, 'eval_micro_precision': 0.8990789473684211, 'eval_micro_recall': 0.8990789473684211, 'eval_macro_f1': 0.898749358348329, 'epoch': 7.0, 'total_flos': 521639885135040}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-92772b76e88bb499.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-8ed9880a16a40baf.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-a3f671cb248fccca.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-f3fb7572504c893f.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 1000, Validation size: 5000, Test size: 7600\n",
            "Augmentation fraction: 0.1\n",
            "{'label': 3, 'text': 'Study: High-tech firms praised for online customer respect While many high-tech firms scored well in a new study of how they treat customers online, more than a third of the surveyed companies still share personal data without permission.'}\n",
            "{'label': 0, 'text': 'Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.'}\n",
            "{'label': 2, 'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='441' max='441' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [441/441 09:38, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.085747</td>\n",
              "      <td>0.333926</td>\n",
              "      <td>0.889200</td>\n",
              "      <td>0.889200</td>\n",
              "      <td>0.889200</td>\n",
              "      <td>0.889200</td>\n",
              "      <td>0.888038</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.291454</td>\n",
              "      <td>0.416902</td>\n",
              "      <td>0.895600</td>\n",
              "      <td>0.895600</td>\n",
              "      <td>0.895600</td>\n",
              "      <td>0.895600</td>\n",
              "      <td>0.894526</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.150313</td>\n",
              "      <td>0.438738</td>\n",
              "      <td>0.898600</td>\n",
              "      <td>0.898600</td>\n",
              "      <td>0.898600</td>\n",
              "      <td>0.898600</td>\n",
              "      <td>0.897860</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.103077</td>\n",
              "      <td>0.469527</td>\n",
              "      <td>0.893600</td>\n",
              "      <td>0.893600</td>\n",
              "      <td>0.893600</td>\n",
              "      <td>0.893600</td>\n",
              "      <td>0.891664</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.080858</td>\n",
              "      <td>0.509908</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.895520</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.043465</td>\n",
              "      <td>0.528000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.897222</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.020246</td>\n",
              "      <td>0.545550</td>\n",
              "      <td>0.893400</td>\n",
              "      <td>0.893400</td>\n",
              "      <td>0.893400</td>\n",
              "      <td>0.893400</td>\n",
              "      <td>0.892851</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [475/475 00:40]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4386281967163086, 'eval_accuracy': 0.900921052631579, 'eval_micro_f1': 0.900921052631579, 'eval_micro_precision': 0.900921052631579, 'eval_micro_recall': 0.900921052631579, 'eval_macro_f1': 0.9009315612557807, 'epoch': 7.0, 'total_flos': 533085628098432}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-92772b76e88bb499.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-8ed9880a16a40baf.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-a3f671cb248fccca.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-f3fb7572504c893f.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 1000, Validation size: 5000, Test size: 7600\n",
            "Augmentation fraction: 0.15\n",
            "{'label': 3, 'text': 'Study: High-tech firms praised for online customer respect While many high-tech firms scored well in a new study of how they treat customers online, more than a third of the surveyed companies still share personal data without permission.'}\n",
            "{'label': 0, 'text': 'Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.'}\n",
            "{'label': 2, 'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='441' max='441' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [441/441 10:39, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.076955</td>\n",
              "      <td>0.343766</td>\n",
              "      <td>0.892000</td>\n",
              "      <td>0.892000</td>\n",
              "      <td>0.892000</td>\n",
              "      <td>0.892000</td>\n",
              "      <td>0.891125</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.312051</td>\n",
              "      <td>0.387500</td>\n",
              "      <td>0.899000</td>\n",
              "      <td>0.899000</td>\n",
              "      <td>0.899000</td>\n",
              "      <td>0.899000</td>\n",
              "      <td>0.898111</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.229256</td>\n",
              "      <td>0.450047</td>\n",
              "      <td>0.893200</td>\n",
              "      <td>0.893200</td>\n",
              "      <td>0.893200</td>\n",
              "      <td>0.893200</td>\n",
              "      <td>0.891514</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.143407</td>\n",
              "      <td>0.445544</td>\n",
              "      <td>0.894600</td>\n",
              "      <td>0.894600</td>\n",
              "      <td>0.894600</td>\n",
              "      <td>0.894600</td>\n",
              "      <td>0.893529</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.080883</td>\n",
              "      <td>0.528602</td>\n",
              "      <td>0.894400</td>\n",
              "      <td>0.894400</td>\n",
              "      <td>0.894400</td>\n",
              "      <td>0.894400</td>\n",
              "      <td>0.893708</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.041424</td>\n",
              "      <td>0.594587</td>\n",
              "      <td>0.887400</td>\n",
              "      <td>0.887400</td>\n",
              "      <td>0.887400</td>\n",
              "      <td>0.887400</td>\n",
              "      <td>0.886700</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.029228</td>\n",
              "      <td>0.572906</td>\n",
              "      <td>0.892600</td>\n",
              "      <td>0.892600</td>\n",
              "      <td>0.892600</td>\n",
              "      <td>0.892600</td>\n",
              "      <td>0.891889</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [475/475 00:42]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3811330795288086, 'eval_accuracy': 0.8994736842105263, 'eval_micro_f1': 0.8994736842105263, 'eval_micro_precision': 0.8994736842105263, 'eval_micro_recall': 0.8994736842105263, 'eval_macro_f1': 0.8994801678260571, 'epoch': 7.0, 'total_flos': 541204746342720}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-92772b76e88bb499.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-8ed9880a16a40baf.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-a3f671cb248fccca.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-f3fb7572504c893f.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 1000, Validation size: 5000, Test size: 7600\n",
            "Augmentation fraction: 0.2\n",
            "{'label': 3, 'text': 'Study: High-tech firms praised for online customer respect While many high-tech firms scored well in a new study of how they treat customers online, more than a third of the surveyed companies still share personal data without permission.'}\n",
            "{'label': 0, 'text': 'Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.'}\n",
            "{'label': 2, 'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='441' max='441' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [441/441 11:41, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.043505</td>\n",
              "      <td>0.335528</td>\n",
              "      <td>0.890800</td>\n",
              "      <td>0.890800</td>\n",
              "      <td>0.890800</td>\n",
              "      <td>0.890800</td>\n",
              "      <td>0.889724</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.283229</td>\n",
              "      <td>0.385604</td>\n",
              "      <td>0.899200</td>\n",
              "      <td>0.899200</td>\n",
              "      <td>0.899200</td>\n",
              "      <td>0.899200</td>\n",
              "      <td>0.897686</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.201062</td>\n",
              "      <td>0.532861</td>\n",
              "      <td>0.883000</td>\n",
              "      <td>0.883000</td>\n",
              "      <td>0.883000</td>\n",
              "      <td>0.883000</td>\n",
              "      <td>0.879746</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.108211</td>\n",
              "      <td>0.500681</td>\n",
              "      <td>0.888800</td>\n",
              "      <td>0.888800</td>\n",
              "      <td>0.888800</td>\n",
              "      <td>0.888800</td>\n",
              "      <td>0.887198</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.078549</td>\n",
              "      <td>0.532912</td>\n",
              "      <td>0.895200</td>\n",
              "      <td>0.895200</td>\n",
              "      <td>0.895200</td>\n",
              "      <td>0.895200</td>\n",
              "      <td>0.894250</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.051241</td>\n",
              "      <td>0.600502</td>\n",
              "      <td>0.889200</td>\n",
              "      <td>0.889200</td>\n",
              "      <td>0.889200</td>\n",
              "      <td>0.889200</td>\n",
              "      <td>0.888355</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.033548</td>\n",
              "      <td>0.585601</td>\n",
              "      <td>0.894000</td>\n",
              "      <td>0.894000</td>\n",
              "      <td>0.894000</td>\n",
              "      <td>0.894000</td>\n",
              "      <td>0.893155</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [475/475 00:42]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.3890441954135895, 'eval_accuracy': 0.8994736842105263, 'eval_micro_f1': 0.8994736842105263, 'eval_micro_precision': 0.8994736842105263, 'eval_micro_recall': 0.8994736842105263, 'eval_macro_f1': 0.8989748134827243, 'epoch': 7.0, 'total_flos': 549030690825792}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-92772b76e88bb499.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-8ed9880a16a40baf.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-a3f671cb248fccca.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-f3fb7572504c893f.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 1000, Validation size: 5000, Test size: 7600\n",
            "Augmentation fraction: 0.25\n",
            "{'label': 3, 'text': 'Study: High-tech firms are praised online for having of online customer respect While many high-tech firms have scored well in a new study of how well they treat customers online, more than a full third of the surveyed companies still routinely share personal data without their permission.'}\n",
            "{'label': 0, 'text': 'Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.'}\n",
            "{'label': 2, 'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='441' max='441' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [441/441 12:43, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.034505</td>\n",
              "      <td>0.326147</td>\n",
              "      <td>0.897000</td>\n",
              "      <td>0.897000</td>\n",
              "      <td>0.897000</td>\n",
              "      <td>0.897000</td>\n",
              "      <td>0.895816</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.274696</td>\n",
              "      <td>0.413627</td>\n",
              "      <td>0.884400</td>\n",
              "      <td>0.884400</td>\n",
              "      <td>0.884400</td>\n",
              "      <td>0.884400</td>\n",
              "      <td>0.884167</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.208459</td>\n",
              "      <td>0.422043</td>\n",
              "      <td>0.899200</td>\n",
              "      <td>0.899200</td>\n",
              "      <td>0.899200</td>\n",
              "      <td>0.899200</td>\n",
              "      <td>0.897847</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.122627</td>\n",
              "      <td>0.463217</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.897143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.087497</td>\n",
              "      <td>0.499697</td>\n",
              "      <td>0.898600</td>\n",
              "      <td>0.898600</td>\n",
              "      <td>0.898600</td>\n",
              "      <td>0.898600</td>\n",
              "      <td>0.897577</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.045072</td>\n",
              "      <td>0.549655</td>\n",
              "      <td>0.893000</td>\n",
              "      <td>0.893000</td>\n",
              "      <td>0.893000</td>\n",
              "      <td>0.893000</td>\n",
              "      <td>0.892434</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.050220</td>\n",
              "      <td>0.544137</td>\n",
              "      <td>0.895800</td>\n",
              "      <td>0.895800</td>\n",
              "      <td>0.895800</td>\n",
              "      <td>0.895800</td>\n",
              "      <td>0.894991</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [475/475 00:42]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.43237581849098206, 'eval_accuracy': 0.8978947368421053, 'eval_micro_f1': 0.8978947368421053, 'eval_micro_precision': 0.8978947368421053, 'eval_micro_recall': 0.8978947368421053, 'eval_macro_f1': 0.8977079834037273, 'epoch': 7.0, 'total_flos': 558920817913344}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-92772b76e88bb499.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-8ed9880a16a40baf.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-a3f671cb248fccca.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-f3fb7572504c893f.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 1000, Validation size: 5000, Test size: 7600\n",
            "Augmentation fraction: 0.3\n",
            "{'label': 3, 'text': 'Study: High-tech firms still praised for online customer respect While many American high-tech firms scored well in a new study because of how they treat customers online, more heavily than a third percent of the surveyed companies still share their own personal browsing data -- without their permission. Bloomberg'}\n",
            "{'label': 0, 'text': 'Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.'}\n",
            "{'label': 2, 'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='441' max='441' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [441/441 13:30, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.052097</td>\n",
              "      <td>0.351068</td>\n",
              "      <td>0.879800</td>\n",
              "      <td>0.879800</td>\n",
              "      <td>0.879800</td>\n",
              "      <td>0.879800</td>\n",
              "      <td>0.878320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.324054</td>\n",
              "      <td>0.454886</td>\n",
              "      <td>0.871200</td>\n",
              "      <td>0.871200</td>\n",
              "      <td>0.871200</td>\n",
              "      <td>0.871200</td>\n",
              "      <td>0.870124</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.190646</td>\n",
              "      <td>0.404573</td>\n",
              "      <td>0.898600</td>\n",
              "      <td>0.898600</td>\n",
              "      <td>0.898600</td>\n",
              "      <td>0.898600</td>\n",
              "      <td>0.897214</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.143448</td>\n",
              "      <td>0.431504</td>\n",
              "      <td>0.892800</td>\n",
              "      <td>0.892800</td>\n",
              "      <td>0.892800</td>\n",
              "      <td>0.892800</td>\n",
              "      <td>0.891842</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.099777</td>\n",
              "      <td>0.497693</td>\n",
              "      <td>0.899400</td>\n",
              "      <td>0.899400</td>\n",
              "      <td>0.899400</td>\n",
              "      <td>0.899400</td>\n",
              "      <td>0.897993</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.052760</td>\n",
              "      <td>0.545629</td>\n",
              "      <td>0.894400</td>\n",
              "      <td>0.894400</td>\n",
              "      <td>0.894400</td>\n",
              "      <td>0.894400</td>\n",
              "      <td>0.893607</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.046669</td>\n",
              "      <td>0.538941</td>\n",
              "      <td>0.896800</td>\n",
              "      <td>0.896800</td>\n",
              "      <td>0.896800</td>\n",
              "      <td>0.896800</td>\n",
              "      <td>0.896145</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [475/475 00:42]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.504808783531189, 'eval_accuracy': 0.8998684210526315, 'eval_micro_f1': 0.8998684210526315, 'eval_micro_precision': 0.8998684210526315, 'eval_micro_recall': 0.8998684210526315, 'eval_macro_f1': 0.8992857316042822, 'epoch': 7.0, 'total_flos': 568505804963712}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-92772b76e88bb499.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-8ed9880a16a40baf.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-a3f671cb248fccca.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-f3fb7572504c893f.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 1000, Validation size: 5000, Test size: 7600\n",
            "Augmentation fraction: 0.4\n",
            "{'label': 3, 'text': 'Study: Most High-tech firms praised more for handling online with customer respect While many high-tech tech firms have scored quite well , in a sweeping new study of how they treat customers treated online, in more than than a third out of the surveyed technology companies still share personal data online without permission.'}\n",
            "{'label': 0, 'text': 'Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.'}\n",
            "{'label': 2, 'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='441' max='441' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [441/441 15:35, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.989870</td>\n",
              "      <td>0.342036</td>\n",
              "      <td>0.888800</td>\n",
              "      <td>0.888800</td>\n",
              "      <td>0.888800</td>\n",
              "      <td>0.888800</td>\n",
              "      <td>0.887403</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.296825</td>\n",
              "      <td>0.375268</td>\n",
              "      <td>0.897600</td>\n",
              "      <td>0.897600</td>\n",
              "      <td>0.897600</td>\n",
              "      <td>0.897600</td>\n",
              "      <td>0.896781</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.215707</td>\n",
              "      <td>0.394140</td>\n",
              "      <td>0.897600</td>\n",
              "      <td>0.897600</td>\n",
              "      <td>0.897600</td>\n",
              "      <td>0.897600</td>\n",
              "      <td>0.895807</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.111277</td>\n",
              "      <td>0.437126</td>\n",
              "      <td>0.900200</td>\n",
              "      <td>0.900200</td>\n",
              "      <td>0.900200</td>\n",
              "      <td>0.900200</td>\n",
              "      <td>0.898946</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.091568</td>\n",
              "      <td>0.496221</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.900000</td>\n",
              "      <td>0.898658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.027712</td>\n",
              "      <td>0.541537</td>\n",
              "      <td>0.896200</td>\n",
              "      <td>0.896200</td>\n",
              "      <td>0.896200</td>\n",
              "      <td>0.896200</td>\n",
              "      <td>0.895493</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.019036</td>\n",
              "      <td>0.535753</td>\n",
              "      <td>0.899000</td>\n",
              "      <td>0.899000</td>\n",
              "      <td>0.899000</td>\n",
              "      <td>0.899000</td>\n",
              "      <td>0.898172</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [475/475 00:42]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.43537232279777527, 'eval_accuracy': 0.9003947368421052, 'eval_micro_f1': 0.9003947368421052, 'eval_micro_precision': 0.9003947368421052, 'eval_micro_recall': 0.9003947368421052, 'eval_macro_f1': 0.8999553589925642, 'epoch': 7.0, 'total_flos': 590834875920000}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-92772b76e88bb499.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-8ed9880a16a40baf.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-a3f671cb248fccca.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-f3fb7572504c893f.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 1000, Validation size: 5000, Test size: 7600\n",
            "Augmentation fraction: 0.5\n",
            "{'label': 3, 'text': 'Study: High-tech tech firms praised for online customer information respect While many US high-tech firms have scored the ably well , in a relatively new study , of customers how they should treat customers online, found showed more than a quarter third majority of the surveyed companies still share personal customer data sometimes without permission. </s> Advertisement'}\n",
            "{'label': 0, 'text': 'Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.'}\n",
            "{'label': 2, 'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='441' max='441' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [441/441 18:35, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.080442</td>\n",
              "      <td>0.347550</td>\n",
              "      <td>0.890200</td>\n",
              "      <td>0.890200</td>\n",
              "      <td>0.890200</td>\n",
              "      <td>0.890200</td>\n",
              "      <td>0.889059</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.295820</td>\n",
              "      <td>0.402843</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.895388</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.204686</td>\n",
              "      <td>0.441853</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.896400</td>\n",
              "      <td>0.894436</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.130752</td>\n",
              "      <td>0.431795</td>\n",
              "      <td>0.899400</td>\n",
              "      <td>0.899400</td>\n",
              "      <td>0.899400</td>\n",
              "      <td>0.899400</td>\n",
              "      <td>0.897799</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.117960</td>\n",
              "      <td>0.473886</td>\n",
              "      <td>0.901600</td>\n",
              "      <td>0.901600</td>\n",
              "      <td>0.901600</td>\n",
              "      <td>0.901600</td>\n",
              "      <td>0.900320</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.065277</td>\n",
              "      <td>0.511074</td>\n",
              "      <td>0.895400</td>\n",
              "      <td>0.895400</td>\n",
              "      <td>0.895400</td>\n",
              "      <td>0.895400</td>\n",
              "      <td>0.894641</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.043268</td>\n",
              "      <td>0.515341</td>\n",
              "      <td>0.898400</td>\n",
              "      <td>0.898400</td>\n",
              "      <td>0.898400</td>\n",
              "      <td>0.898400</td>\n",
              "      <td>0.897760</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [475/475 00:42]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.47995609045028687, 'eval_accuracy': 0.901578947368421, 'eval_micro_f1': 0.901578947368421, 'eval_micro_precision': 0.901578947368421, 'eval_micro_recall': 0.901578947368421, 'eval_macro_f1': 0.9013605170169923, 'epoch': 7.0, 'total_flos': 610698894026880}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-92772b76e88bb499.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-8ed9880a16a40baf.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-a3f671cb248fccca.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-f3fb7572504c893f.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 1000, Validation size: 5000, Test size: 7600\n",
            "Augmentation fraction: 0.6\n",
            "{'label': 3, 'text': 'Study: High-tech firms praised best for showing on online customer respect While many US high-tech firms scored high as well received in a a new Harvard study of the how they would treat customers online, in more than half a quarter and third of all the companies surveyed , companies still share their personal location data without permission. Read Advertisement'}\n",
            "{'label': 0, 'text': 'Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.'}\n",
            "{'label': 2, 'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='441' max='441' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [441/441 21:06, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.070023</td>\n",
              "      <td>0.340561</td>\n",
              "      <td>0.889200</td>\n",
              "      <td>0.889200</td>\n",
              "      <td>0.889200</td>\n",
              "      <td>0.889200</td>\n",
              "      <td>0.888314</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.302426</td>\n",
              "      <td>0.410830</td>\n",
              "      <td>0.884800</td>\n",
              "      <td>0.884800</td>\n",
              "      <td>0.884800</td>\n",
              "      <td>0.884800</td>\n",
              "      <td>0.884861</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.207484</td>\n",
              "      <td>0.426536</td>\n",
              "      <td>0.893400</td>\n",
              "      <td>0.893400</td>\n",
              "      <td>0.893400</td>\n",
              "      <td>0.893400</td>\n",
              "      <td>0.891721</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.146251</td>\n",
              "      <td>0.460726</td>\n",
              "      <td>0.887400</td>\n",
              "      <td>0.887400</td>\n",
              "      <td>0.887400</td>\n",
              "      <td>0.887400</td>\n",
              "      <td>0.885490</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.125268</td>\n",
              "      <td>0.484938</td>\n",
              "      <td>0.893000</td>\n",
              "      <td>0.893000</td>\n",
              "      <td>0.893000</td>\n",
              "      <td>0.893000</td>\n",
              "      <td>0.891734</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.058905</td>\n",
              "      <td>0.553756</td>\n",
              "      <td>0.886000</td>\n",
              "      <td>0.886000</td>\n",
              "      <td>0.886000</td>\n",
              "      <td>0.886000</td>\n",
              "      <td>0.885502</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.073028</td>\n",
              "      <td>0.527891</td>\n",
              "      <td>0.892600</td>\n",
              "      <td>0.892600</td>\n",
              "      <td>0.892600</td>\n",
              "      <td>0.892600</td>\n",
              "      <td>0.891873</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [475/475 00:42]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4387001395225525, 'eval_accuracy': 0.8903947368421052, 'eval_micro_f1': 0.8903947368421052, 'eval_micro_precision': 0.8903947368421052, 'eval_micro_recall': 0.8903947368421052, 'eval_macro_f1': 0.8902036175280332, 'epoch': 7.0, 'total_flos': 631364652623616}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForSequenceClassification: ['lm_head.bias', 'lm_head.dense.weight', 'lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.layer_norm.bias', 'lm_head.decoder.weight', 'roberta.pooler.dense.weight', 'roberta.pooler.dense.bias']\n",
            "- This IS expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPretraining model).\n",
            "- This IS NOT expected if you are initializing RobertaForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Using custom data configuration default\n",
            "Reusing dataset ag_news (/root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a)\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-92772b76e88bb499.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-8ed9880a16a40baf.arrow\n",
            "Loading cached split indices for dataset at /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-a3f671cb248fccca.arrow and /root/.cache/huggingface/datasets/ag_news/default/0.0.0/fb5c5e74a110037311ef5e904583ce9f8b9fbc1354290f97b4929f01b3f48b1a/cache-f3fb7572504c893f.arrow\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train size: 1000, Validation size: 5000, Test size: 7600\n",
            "Augmentation fraction: 0.7\n",
            "{'label': 3, 'text': 'Study: High-tech firms praised for online customer respect While many high-tech firms scored well in a new study of how they treat customers online, more than a third of the surveyed companies still share personal data without permission.'}\n",
            "{'label': 0, 'text': 'Bangladesh paralysed by strikes Opposition activists have brought many towns and cities in Bangladesh to a halt, the day after 18 people died in explosions at a political rally.'}\n",
            "{'label': 2, 'text': \"Fears for T N pension after talks Unions representing workers at Turner   Newall say they are 'disappointed' after talks with stricken parent firm Federal Mogul.\"}\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='441' max='441' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [441/441 22:34, Epoch 7/7]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>Micro F1</th>\n",
              "      <th>Micro Precision</th>\n",
              "      <th>Micro Recall</th>\n",
              "      <th>Macro F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>1.150230</td>\n",
              "      <td>0.342911</td>\n",
              "      <td>0.892000</td>\n",
              "      <td>0.892000</td>\n",
              "      <td>0.892000</td>\n",
              "      <td>0.892000</td>\n",
              "      <td>0.891194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.315760</td>\n",
              "      <td>0.397115</td>\n",
              "      <td>0.890600</td>\n",
              "      <td>0.890600</td>\n",
              "      <td>0.890600</td>\n",
              "      <td>0.890600</td>\n",
              "      <td>0.889578</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.227548</td>\n",
              "      <td>0.405416</td>\n",
              "      <td>0.894400</td>\n",
              "      <td>0.894400</td>\n",
              "      <td>0.894400</td>\n",
              "      <td>0.894400</td>\n",
              "      <td>0.893160</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.125253</td>\n",
              "      <td>0.495308</td>\n",
              "      <td>0.886800</td>\n",
              "      <td>0.886800</td>\n",
              "      <td>0.886800</td>\n",
              "      <td>0.886800</td>\n",
              "      <td>0.884705</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.135469</td>\n",
              "      <td>0.468169</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.898000</td>\n",
              "      <td>0.896971</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>6</td>\n",
              "      <td>0.073133</td>\n",
              "      <td>0.534484</td>\n",
              "      <td>0.893200</td>\n",
              "      <td>0.893200</td>\n",
              "      <td>0.893200</td>\n",
              "      <td>0.893200</td>\n",
              "      <td>0.892219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>7</td>\n",
              "      <td>0.057382</td>\n",
              "      <td>0.528442</td>\n",
              "      <td>0.895800</td>\n",
              "      <td>0.895800</td>\n",
              "      <td>0.895800</td>\n",
              "      <td>0.895800</td>\n",
              "      <td>0.894750</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "    <div>\n",
              "        <style>\n",
              "            /* Turns off some styling */\n",
              "            progress {\n",
              "                /* gets rid of default border in Firefox and Opera. */\n",
              "                border: none;\n",
              "                /* Needs to be in here for Safari polyfill so background images work as expected. */\n",
              "                background-size: auto;\n",
              "            }\n",
              "        </style>\n",
              "      \n",
              "      <progress value='475' max='475' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [475/475 00:42]\n",
              "    </div>\n",
              "    "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "{'eval_loss': 0.4789787828922272, 'eval_accuracy': 0.8982894736842105, 'eval_micro_f1': 0.8982894736842105, 'eval_micro_precision': 0.8982894736842105, 'eval_micro_recall': 0.8982894736842105, 'eval_macro_f1': 0.8982002287176518, 'epoch': 7.0, 'total_flos': 651575692733568}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GT0fA71t9DIX",
        "outputId": "dfa75341-46c6-45d5-b096-3c73b7efa3a0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        }
      },
      "source": [
        "plt.plot(FRACTIONS, accuracies)\n",
        "plt.xlabel('augmentation stength')\n",
        "plt.ylabel('accuracy')\n",
        "plt.title('AG News dataset');"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}